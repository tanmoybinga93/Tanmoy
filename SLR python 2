import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
salary_data = pd.read_csv('Salary_Data.csv')
salary_data
YearsExperience	Salary
0	1.1	39343.0
1	1.3	46205.0
2	1.5	37731.0
3	2.0	43525.0
4	2.2	39891.0
5	2.9	56642.0
6	3.0	60150.0
7	3.2	54445.0
8	3.2	64445.0
9	3.7	57189.0
10	3.9	63218.0
11	4.0	55794.0
12	4.0	56957.0
13	4.1	57081.0
14	4.5	61111.0
15	4.9	67938.0
16	5.1	66029.0
17	5.3	83088.0
18	5.9	81363.0
19	6.0	93940.0
20	6.8	91738.0
21	7.1	98273.0
22	7.9	101302.0
23	8.2	113812.0
24	8.7	109431.0
25	9.0	105582.0
26	9.5	116969.0
27	9.6	112635.0
28	10.3	122391.0
29	10.5	121872.0
str(salary_data)
'    YearsExperience    Salary\n0               1.1   39343.0\n1               1.3   46205.0\n2               1.5   37731.0\n3               2.0   43525.0\n4               2.2   39891.0\n5               2.9   56642.0\n6               3.0   60150.0\n7               3.2   54445.0\n8               3.2   64445.0\n9               3.7   57189.0\n10              3.9   63218.0\n11              4.0   55794.0\n12              4.0   56957.0\n13              4.1   57081.0\n14              4.5   61111.0\n15              4.9   67938.0\n16              5.1   66029.0\n17              5.3   83088.0\n18              5.9   81363.0\n19              6.0   93940.0\n20              6.8   91738.0\n21              7.1   98273.0\n22              7.9  101302.0\n23              8.2  113812.0\n24              8.7  109431.0\n25              9.0  105582.0\n26              9.5  116969.0\n27              9.6  112635.0\n28             10.3  122391.0\n29             10.5  121872.0'
salary_data.head()
YearsExperience	Salary
0	1.1	39343.0
1	1.3	46205.0
2	1.5	37731.0
3	2.0	43525.0
4	2.2	39891.0
salary_data.tail()
YearsExperience	Salary
25	9.0	105582.0
26	9.5	116969.0
27	9.6	112635.0
28	10.3	122391.0
29	10.5	121872.0
salary_data.columns
Index(['YearsExperience', 'Salary'], dtype='object')
plt.hist(salary_data.YearsExperience)
(array([4., 2., 5., 4., 3., 2., 2., 2., 3., 3.]),
 array([ 1.1 ,  2.04,  2.98,  3.92,  4.86,  5.8 ,  6.74,  7.68,  8.62,
         9.56, 10.5 ]),
 <a list of 10 Patch objects>)

plt.hist(salary_data.Salary)
(array([4., 2., 7., 4., 0., 2., 2., 2., 4., 3.]),
 array([ 37731.,  46197.,  54663.,  63129.,  71595.,  80061.,  88527.,
         96993., 105459., 113925., 122391.]),
 <a list of 10 Patch objects>)

plt.boxplot(salary_data.Salary)
{'whiskers': [<matplotlib.lines.Line2D at 0x25b92569d08>,
  <matplotlib.lines.Line2D at 0x25b92570988>],
 'caps': [<matplotlib.lines.Line2D at 0x25b92577308>,
  <matplotlib.lines.Line2D at 0x25b9257a8c8>],
 'boxes': [<matplotlib.lines.Line2D at 0x25b9255c9c8>],
 'medians': [<matplotlib.lines.Line2D at 0x25b9257ed88>],
 'fliers': [<matplotlib.lines.Line2D at 0x25b92587d88>],
 'means': []}

plt.plot(salary_data.Salary,salary_data.YearsExperience,"ro");plt.xlabel("YearsExperience");plt.ylabel("Salary")
Text(0, 0.5, 'Salary')

salary_data.corr()
YearsExperience	Salary
YearsExperience	1.000000	0.978242
Salary	0.978242	1.000000
salary_data.Salary.corr(salary_data.YearsExperience)
0.9782416184887598
np.corrcoef(salary_data.Salary,salary_data.YearsExperience)
array([[1.        , 0.97824162],
       [0.97824162, 1.        ]])
##### for preparing linear model we need to import statsmodels.formula.api
import statsmodels.formula.api as smf 
model = smf.ols("YearsExperience~Salary",data = salary_data).fit()
model
<statsmodels.regression.linear_model.RegressionResultsWrapper at 0x25b97512e08>
type(model)
statsmodels.regression.linear_model.RegressionResultsWrapper
model.summary()
OLS Regression Results
Dep. Variable:	YearsExperience	R-squared:	0.957
Model:	OLS	Adj. R-squared:	0.955
Method:	Least Squares	F-statistic:	622.5
Date:	Sat, 22 Aug 2020	Prob (F-statistic):	1.14e-20
Time:	19:01:47	Log-Likelihood:	-26.168
No. Observations:	30	AIC:	56.34
Df Residuals:	28	BIC:	59.14
Df Model:	1		
Covariance Type:	nonrobust		
coef	std err	t	P>|t|	[0.025	0.975]
Intercept	-2.3832	0.327	-7.281	0.000	-3.054	-1.713
Salary	0.0001	4.06e-06	24.950	0.000	9.3e-05	0.000
Omnibus:	3.544	Durbin-Watson:	1.587
Prob(Omnibus):	0.170	Jarque-Bera (JB):	2.094
Skew:	-0.412	Prob(JB):	0.351
Kurtosis:	2.003	Cond. No.	2.41e+05


Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The condition number is large, 2.41e+05. This might indicate that there are
strong multicollinearity or other numerical problems.
model.conf_int(0.95)
0	1
Intercept	-2.403869	-2.362452
Salary	0.000101	0.000102
prediction = model.predict(salary_data.Salary)
prediction
0      1.600934
1      2.295819
2      1.437694
3      2.024427
4      1.656428
5      3.352729
6      3.707969
7      3.130248
8      4.142905
9      3.408121
10     4.018652
11     3.266856
12     3.384628
13     3.397185
14     3.805285
15     4.496626
16     4.303310
17     6.030801
18     5.856117
19     7.129735
20     6.906748
21     7.568520
22     7.875253
23     9.142087
24     8.698442
25     8.308670
26     9.461782
27     9.022897
28    10.010845
29     9.958288
dtype: float64
plt.scatter(x = salary_data['YearsExperience'],y = salary_data['Salary'],color = 'red');plt.plot(salary_data['YearsExperience'],prediction,color = 'black');plt.xlabel('YearsExperience');plt.ylabel('Salary') 
Text(0, 0.5, 'Salary')

prediction.corr(salary_data.Salary)
0.9999999999999999
####### transforming variables for accuracy ########## 

model12 = smf.ols('Salary~np.log(YearsExperience)',data = salary_data).fit()
model12.params
Intercept                  14927.97177
np.log(YearsExperience)    40581.98796
dtype: float64
model12.summary()
OLS Regression Results
Dep. Variable:	Salary	R-squared:	0.854
Model:	OLS	Adj. R-squared:	0.849
Method:	Least Squares	F-statistic:	163.6
Date:	Sat, 22 Aug 2020	Prob (F-statistic):	3.25e-13
Time:	19:26:04	Log-Likelihood:	-319.77
No. Observations:	30	AIC:	643.5
Df Residuals:	28	BIC:	646.3
Df Model:	1		
Covariance Type:	nonrobust		
coef	std err	t	P>|t|	[0.025	0.975]
Intercept	1.493e+04	5156.226	2.895	0.007	4365.921	2.55e+04
np.log(YearsExperience)	4.058e+04	3172.453	12.792	0.000	3.41e+04	4.71e+04
Omnibus:	1.094	Durbin-Watson:	0.512
Prob(Omnibus):	0.579	Jarque-Bera (JB):	0.908
Skew:	0.156	Prob(JB):	0.635
Kurtosis:	2.207	Cond. No.	5.76


Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
print(model12.conf_int(0.01))
                                    0             1
Intercept                  679.965646  29175.977894
np.log(YearsExperience)  31815.666558  49348.309362
pred2 = model12.predict(salary_data)
pred2.corr(salary_data.Salary)
0.9240610817882637
pred2 = model12.predict(salary_data.iloc[:,0])
pred2
0      18795.848339
1      25575.235192
2      31382.551905
3      43057.262306
4      46925.138875
5      58136.050079
6      59511.842441
7      62130.943929
8      62130.943929
9      68022.718504
10     70159.105863
11     71186.552842
12     71186.552842
13     72188.628149
14     75966.422577
15     79422.295729
16     81045.791737
17     82606.829882
18     86959.066704
19     87641.132977
20     92720.502137
21     94472.514696
22     98805.371390
23    100317.918684
24    102719.920751
25    104095.713112
26    106289.868435
27    106714.814600
28    109571.007247
29    110351.454145
dtype: float64
plt.scatter(x=salary_data['YearsExperience'],y=salary_data['Salary'],color='green');plt.plot(salary_data['YearsExperience'],pred2,color='blue');plt.xlabel('YearsExperience');plt.ylabel('Salary')
Text(0, 0.5, 'Salary')

###### exponential transformation ########### 

model13 = smf.ols('np.log(Salary)~YearsExperience',data = salary_data).fit()
model13.params
Intercept          10.507402
YearsExperience     0.125453
dtype: float64
model13.summary()
OLS Regression Results
Dep. Variable:	np.log(Salary)	R-squared:	0.932
Model:	OLS	Adj. R-squared:	0.930
Method:	Least Squares	F-statistic:	383.6
Date:	Sat, 22 Aug 2020	Prob (F-statistic):	7.03e-18
Time:	19:42:52	Log-Likelihood:	28.183
No. Observations:	30	AIC:	-52.37
Df Residuals:	28	BIC:	-49.56
Df Model:	1		
Covariance Type:	nonrobust		
coef	std err	t	P>|t|	[0.025	0.975]
Intercept	10.5074	0.038	273.327	0.000	10.429	10.586
YearsExperience	0.1255	0.006	19.585	0.000	0.112	0.139
Omnibus:	0.826	Durbin-Watson:	1.438
Prob(Omnibus):	0.661	Jarque-Bera (JB):	0.812
Skew:	0.187	Prob(JB):	0.666
Kurtosis:	2.286	Cond. No.	13.2


Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
print(model13.conf_int(0.01))
                         0          1
Intercept        10.401175  10.613629
YearsExperience   0.107752   0.143153
pred_log = model13.predict(salary_data)
pred_log
0     10.645400
1     10.670491
2     10.695581
3     10.758308
4     10.783398
5     10.871215
6     10.883761
7     10.908851
8     10.908851
9     10.971578
10    10.996668
11    11.009213
12    11.009213
13    11.021759
14    11.071940
15    11.122121
16    11.147212
17    11.172302
18    11.247574
19    11.260119
20    11.360482
21    11.398117
22    11.498480
23    11.536116
24    11.598842
25    11.636478
26    11.699204
27    11.711750
28    11.799567
29    11.824657
dtype: float64
pred3 = np.exp(pred_log)
pred3
0      41998.957468
1      43066.066794
2      44160.289228
3      47019.029189
4      48213.688474
5      52639.142472
6      53303.675386
7      54658.014935
8      54658.014935
9      58196.330788
10     59674.982903
11     60428.338456
12     60428.338456
13     61191.204604
14     64340.199291
15     67651.246149
16     69370.128712
17     71132.684635
18     76693.630780
19     77661.835040
20     85860.704208
21     89153.725393
22     98565.809591
23    102346.110512
24    108971.540758
25    113150.933364
26    120475.819601
27    121996.743836
28    133194.621344
29    136578.829694
dtype: float64
pred3.corr(salary_data.Salary)
plt.scatter(x=salary_data['YearsExperience'],y=salary_data['Salary'],color='green');plt.plot(salary_data.YearsExperience,np.exp(pred_log),color='blue');plt.xlabel('YearsExperience');plt.ylabel('Salary')
Text(0, 0.5, 'Salary')

# Quadratic model
salary_data["YearsExperience_Sq"] = salary_data.YearsExperience*salary_data.YearsExperience
model_quad = smf.ols("Salary~YearsExperience+YearsExperience_Sq",data=salary_data).fit()
model_quad.params
Intercept             26214.932677
YearsExperience        9259.283888
YearsExperience_Sq       16.392566
dtype: float64
model_quad.summary()
OLS Regression Results
Dep. Variable:	Salary	R-squared:	0.957
Model:	OLS	Adj. R-squared:	0.954
Method:	Least Squares	F-statistic:	300.3
Date:	Sat, 22 Aug 2020	Prob (F-statistic):	3.59e-19
Time:	20:06:38	Log-Likelihood:	-301.43
No. Observations:	30	AIC:	608.9
Df Residuals:	27	BIC:	613.1
Df Model:	2		
Covariance Type:	nonrobust		
coef	std err	t	P>|t|	[0.025	0.975]
Intercept	2.621e+04	4554.674	5.756	0.000	1.69e+04	3.56e+04
YearsExperience	9259.2839	1811.007	5.113	0.000	5543.405	1.3e+04
YearsExperience_Sq	16.3926	152.121	0.108	0.915	-295.734	328.520
Omnibus:	2.181	Durbin-Watson:	1.649
Prob(Omnibus):	0.336	Jarque-Bera (JB):	1.627
Skew:	0.384	Prob(JB):	0.443
Kurtosis:	2.156	Cond. No.	223.


Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
pred_quad = model_quad.predict(salary_data)
model_quad.conf_int(0.05)
0	1
Intercept	16869.512653	35560.352701
YearsExperience	5543.405004	12975.162772
YearsExperience_Sq	-295.734369	328.519502
plt.scatter(salary_data.YearsExperience,salary_data.Salary,c="b");plt.plot(salary_data.YearsExperience,pred_quad,"r")
[<matplotlib.lines.Line2D at 0x25b97c11d08>]

plt.scatter(np.arange(109),model_quad.resid_pearson);plt.axhline(y=0,color='red');plt.xlabel("Observation Number");plt.ylabel("Standardized Residual")
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
<ipython-input-70-9922d90d455f> in <module>
----> 1 plt.scatter(np.arange(109),model_quad.resid_pearson);plt.axhline(y=0,color='red');plt.xlabel("Observation Number");plt.ylabel("Standardized Residual")
      2 

~\anaconda3\lib\site-packages\matplotlib\pyplot.py in scatter(x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, plotnonfinite, data, **kwargs)
   2846         verts=verts, edgecolors=edgecolors,
   2847         plotnonfinite=plotnonfinite, **({"data": data} if data is not
-> 2848         None else {}), **kwargs)
   2849     sci(__ret)
   2850     return __ret

~\anaconda3\lib\site-packages\matplotlib\__init__.py in inner(ax, data, *args, **kwargs)
   1597     def inner(ax, *args, data=None, **kwargs):
   1598         if data is None:
-> 1599             return func(ax, *map(sanitize_sequence, args), **kwargs)
   1600 
   1601         bound = new_sig.bind(ax, *args, **kwargs)

~\anaconda3\lib\site-packages\matplotlib\axes\_axes.py in scatter(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, plotnonfinite, **kwargs)
   4441         y = np.ma.ravel(y)
   4442         if x.size != y.size:
-> 4443             raise ValueError("x and y must be the same size")
   4444 
   4445         if s is None:

ValueError: x and y must be the same size

plt.hist(model_quad.resid_pearson)
(array([6., 3., 3., 3., 6., 2., 1., 2., 2., 2.]),
 array([-1.32942469, -0.99999975, -0.6705748 , -0.34114986, -0.01172492,
         0.31770002,  0.64712497,  0.97654991,  1.30597485,  1.63539979,
         1.96482474]),
 <a list of 10 Patch objects>)

resid = model_quad.resid_pearson 
resid
plt.plot(pred_quad,model_quad.resid_pearson,"o");plt.axhline(y=0,color='green');plt.xlabel("Observation Number");plt.ylabel("Standardized Residual")
Text(0, 0.5, 'Standardized Residual')

# Predicted vs actual values
plt.scatter(x=pred_quad,y=salary_data.Salary, color='red');plt.xlabel("Predicted", color='green');plt.ylabel("Actual")
Text(0, 0.5, 'Actual')

plt.plot(pred_quad,salary_data.Salary, color='red');plt.xlabel("Predicted", color='green');plt.ylabel("Actual")
Text(0, 0.5, 'Actual')

 
